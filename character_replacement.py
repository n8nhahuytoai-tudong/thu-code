"""
Character Replacement in Video
Thay th·∫ø nh√¢n v·∫≠t trong video s·ª≠ d·ª•ng AI

Module n√†y cung c·∫•p ch·ª©c nƒÉng thay th·∫ø nh√¢n v·∫≠t/ƒë·ªëi t∆∞·ª£ng trong video
b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t AI v√† x·ª≠ l√Ω ·∫£nh.
"""

import cv2
import numpy as np
from pathlib import Path
from typing import Optional, Tuple, List
import json
from datetime import datetime


class CharacterReplacer:
    """Class ƒë·ªÉ thay th·∫ø nh√¢n v·∫≠t trong video"""

    def __init__(self, video_path: str):
        """
        Kh·ªüi t·∫°o CharacterReplacer

        Args:
            video_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file video ƒë·∫ßu v√†o
        """
        self.video_path = Path(video_path)
        if not self.video_path.exists():
            raise FileNotFoundError(f"Video file kh√¥ng t·ªìn t·∫°i: {video_path}")

        self.cap = cv2.VideoCapture(str(self.video_path))
        if not self.cap.isOpened():
            raise ValueError(f"Kh√¥ng th·ªÉ m·ªü video: {video_path}")

        # L·∫•y th√¥ng tin video
        self.fps = self.cap.get(cv2.CAP_PROP_FPS)
        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.duration = self.total_frames / self.fps if self.fps > 0 else 0

        # Kh·ªüi t·∫°o c√°c detector
        self._init_detectors()

    def _init_detectors(self):
        """Kh·ªüi t·∫°o c√°c detector cho face v√† body"""
        try:
            # Face detector (Haar Cascade)
            self.face_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
            )

            # Body detector (Haar Cascade)
            self.body_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + 'haarcascade_fullbody.xml'
            )

            print("‚úì ƒê√£ kh·ªüi t·∫°o face v√† body detectors")
        except Exception as e:
            print(f"‚ö† C·∫£nh b√°o: Kh√¥ng th·ªÉ kh·ªüi t·∫°o detectors: {e}")

    def get_video_info(self) -> dict:
        """L·∫•y th√¥ng tin video"""
        return {
            "filename": self.video_path.name,
            "path": str(self.video_path),
            "resolution": f"{self.width}x{self.height}",
            "fps": self.fps,
            "total_frames": self.total_frames,
            "duration_seconds": self.duration
        }

    def detect_characters(self, frame: np.ndarray) -> List[dict]:
        """
        Ph√°t hi·ªán nh√¢n v·∫≠t trong frame

        Args:
            frame: Frame ·∫£nh t·ª´ video

        Returns:
            List c√°c dictionary ch·ª©a th√¥ng tin nh√¢n v·∫≠t ph√°t hi·ªán ƒë∆∞·ª£c
        """
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        characters = []

        # Ph√°t hi·ªán khu√¥n m·∫∑t
        faces = self.face_cascade.detectMultiScale(
            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)
        )

        for idx, (x, y, w, h) in enumerate(faces):
            characters.append({
                "type": "face",
                "id": idx,
                "bbox": {"x": int(x), "y": int(y), "w": int(w), "h": int(h)},
                "center": {"x": int(x + w/2), "y": int(y + h/2)}
            })

        # Ph√°t hi·ªán body
        bodies = self.body_cascade.detectMultiScale(
            gray, scaleFactor=1.1, minNeighbors=3, minSize=(50, 100)
        )

        for idx, (x, y, w, h) in enumerate(bodies):
            # Ki·ªÉm tra n·∫øu body kh√¥ng tr√πng v·ªõi face ƒë√£ detect
            overlap = False
            for char in characters:
                if char["type"] == "face":
                    fx, fy, fw, fh = char["bbox"]["x"], char["bbox"]["y"], char["bbox"]["w"], char["bbox"]["h"]
                    if self._is_overlapping((x, y, w, h), (fx, fy, fw, fh)):
                        overlap = True
                        break

            if not overlap:
                characters.append({
                    "type": "body",
                    "id": idx,
                    "bbox": {"x": int(x), "y": int(y), "w": int(w), "h": int(h)},
                    "center": {"x": int(x + w/2), "y": int(y + h/2)}
                })

        return characters

    def _is_overlapping(self, box1: Tuple, box2: Tuple, threshold: float = 0.3) -> bool:
        """Ki·ªÉm tra 2 bounding box c√≥ overlap kh√¥ng"""
        x1, y1, w1, h1 = box1
        x2, y2, w2, h2 = box2

        # T√≠nh intersection
        x_left = max(x1, x2)
        y_top = max(y1, y2)
        x_right = min(x1 + w1, x2 + w2)
        y_bottom = min(y1 + h1, y2 + h2)

        if x_right < x_left or y_bottom < y_top:
            return False

        intersection_area = (x_right - x_left) * (y_bottom - y_top)
        box1_area = w1 * h1
        box2_area = w2 * h2

        iou = intersection_area / float(box1_area + box2_area - intersection_area)
        return iou > threshold

    def replace_character_blur(
        self,
        frame: np.ndarray,
        character: dict,
        blur_strength: int = 51
    ) -> np.ndarray:
        """
        Thay th·∫ø nh√¢n v·∫≠t b·∫±ng c√°ch blur v√πng ƒë√≥

        Args:
            frame: Frame g·ªëc
            character: Th√¥ng tin nh√¢n v·∫≠t c·∫ßn thay th·∫ø
            blur_strength: ƒê·ªô m·∫°nh c·ªßa blur (s·ªë l·∫ª)

        Returns:
            Frame ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        """
        result = frame.copy()
        bbox = character["bbox"]
        x, y, w, h = bbox["x"], bbox["y"], bbox["w"], bbox["h"]

        # Blur v√πng nh√¢n v·∫≠t
        roi = result[y:y+h, x:x+w]
        blurred = cv2.GaussianBlur(roi, (blur_strength, blur_strength), 0)
        result[y:y+h, x:x+w] = blurred

        return result

    def replace_character_pixelate(
        self,
        frame: np.ndarray,
        character: dict,
        pixel_size: int = 20
    ) -> np.ndarray:
        """
        Thay th·∫ø nh√¢n v·∫≠t b·∫±ng pixelation/mosaic

        Args:
            frame: Frame g·ªëc
            character: Th√¥ng tin nh√¢n v·∫≠t c·∫ßn thay th·∫ø
            pixel_size: K√≠ch th∆∞·ªõc pixel (c√†ng l·ªõn c√†ng m·ªù)

        Returns:
            Frame ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        """
        result = frame.copy()
        bbox = character["bbox"]
        x, y, w, h = bbox["x"], bbox["y"], bbox["w"], bbox["h"]

        # Pixelate v√πng nh√¢n v·∫≠t
        roi = result[y:y+h, x:x+w]

        # Gi·∫£m k√≠ch th∆∞·ªõc
        temp = cv2.resize(roi, (w // pixel_size, h // pixel_size), interpolation=cv2.INTER_LINEAR)
        # TƒÉng l·∫°i k√≠ch th∆∞·ªõc
        pixelated = cv2.resize(temp, (w, h), interpolation=cv2.INTER_NEAREST)

        result[y:y+h, x:x+w] = pixelated

        return result

    def replace_character_color(
        self,
        frame: np.ndarray,
        character: dict,
        color: Tuple[int, int, int] = (0, 0, 0)
    ) -> np.ndarray:
        """
        Thay th·∫ø nh√¢n v·∫≠t b·∫±ng m√†u ƒë·ªìng nh·∫•t

        Args:
            frame: Frame g·ªëc
            character: Th√¥ng tin nh√¢n v·∫≠t c·∫ßn thay th·∫ø
            color: M√†u thay th·∫ø (B, G, R)

        Returns:
            Frame ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        """
        result = frame.copy()
        bbox = character["bbox"]
        x, y, w, h = bbox["x"], bbox["y"], bbox["w"], bbox["h"]

        # T·∫°o silhouette
        cv2.rectangle(result, (x, y), (x+w, y+h), color, -1)

        return result

    def replace_character_image(
        self,
        frame: np.ndarray,
        character: dict,
        replacement_image_path: str
    ) -> np.ndarray:
        """
        Thay th·∫ø nh√¢n v·∫≠t b·∫±ng ·∫£nh kh√°c

        Args:
            frame: Frame g·ªëc
            character: Th√¥ng tin nh√¢n v·∫≠t c·∫ßn thay th·∫ø
            replacement_image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh thay th·∫ø

        Returns:
            Frame ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        """
        result = frame.copy()
        bbox = character["bbox"]
        x, y, w, h = bbox["x"], bbox["y"], bbox["w"], bbox["h"]

        # ƒê·ªçc ·∫£nh thay th·∫ø
        replacement = cv2.imread(replacement_image_path)
        if replacement is None:
            print(f"‚ö† Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {replacement_image_path}")
            return result

        # Resize ·∫£nh thay th·∫ø ƒë·ªÉ kh·ªõp v·ªõi k√≠ch th∆∞·ªõc nh√¢n v·∫≠t
        replacement_resized = cv2.resize(replacement, (w, h))

        # Thay th·∫ø v√πng nh√¢n v·∫≠t
        result[y:y+h, x:x+w] = replacement_resized

        return result

    def process_video(
        self,
        output_path: str,
        replacement_method: str = "blur",
        replacement_image: Optional[str] = None,
        character_filter: Optional[str] = None,
        show_bboxes: bool = False,
        frame_skip: int = 1
    ) -> dict:
        """
        X·ª≠ l√Ω video v√† thay th·∫ø nh√¢n v·∫≠t

        Args:
            output_path: ƒê∆∞·ªùng d·∫´n l∆∞u video ƒë·∫ßu ra
            replacement_method: Ph∆∞∆°ng ph√°p thay th·∫ø ("blur", "pixelate", "color", "image")
            replacement_image: ƒê∆∞·ªùng d·∫´n ·∫£nh thay th·∫ø (n·∫øu method="image")
            character_filter: L·ªçc lo·∫°i nh√¢n v·∫≠t ("face", "body", None=all)
            show_bboxes: Hi·ªÉn th·ªã bounding boxes
            frame_skip: B·ªè qua n frames (tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω)

        Returns:
            Dictionary ch·ª©a th·ªëng k√™ x·ª≠ l√Ω
        """
        # Kh·ªüi t·∫°o video writer
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, self.fps, (self.width, self.height))

        if not out.isOpened():
            raise ValueError(f"Kh√¥ng th·ªÉ t·∫°o video output: {output_path}")

        stats = {
            "start_time": datetime.now().isoformat(),
            "input_video": str(self.video_path),
            "output_video": output_path,
            "method": replacement_method,
            "frames_processed": 0,
            "characters_replaced": 0,
            "processing_errors": 0
        }

        print(f"\nüé¨ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video...")
        print(f"   Input: {self.video_path.name}")
        print(f"   Output: {output_path}")
        print(f"   Method: {replacement_method}")
        print(f"   Total frames: {self.total_frames}")

        frame_count = 0
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset v·ªÅ frame ƒë·∫ßu

        while True:
            ret, frame = self.cap.read()
            if not ret:
                break

            frame_count += 1

            # Skip frames n·∫øu c·∫ßn
            if frame_count % (frame_skip + 1) != 0:
                out.write(frame)
                continue

            try:
                # Ph√°t hi·ªán nh√¢n v·∫≠t
                characters = self.detect_characters(frame)

                # L·ªçc theo lo·∫°i nh√¢n v·∫≠t n·∫øu c·∫ßn
                if character_filter:
                    characters = [c for c in characters if c["type"] == character_filter]

                # Thay th·∫ø t·ª´ng nh√¢n v·∫≠t
                processed_frame = frame.copy()
                for char in characters:
                    if replacement_method == "blur":
                        processed_frame = self.replace_character_blur(processed_frame, char)
                    elif replacement_method == "pixelate":
                        processed_frame = self.replace_character_pixelate(processed_frame, char)
                    elif replacement_method == "color":
                        processed_frame = self.replace_character_color(processed_frame, char)
                    elif replacement_method == "image" and replacement_image:
                        processed_frame = self.replace_character_image(processed_frame, char, replacement_image)

                    stats["characters_replaced"] += 1

                    # V·∫Ω bounding box n·∫øu c·∫ßn
                    if show_bboxes:
                        bbox = char["bbox"]
                        cv2.rectangle(
                            processed_frame,
                            (bbox["x"], bbox["y"]),
                            (bbox["x"] + bbox["w"], bbox["y"] + bbox["h"]),
                            (0, 255, 0), 2
                        )
                        cv2.putText(
                            processed_frame,
                            char["type"],
                            (bbox["x"], bbox["y"] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.5,
                            (0, 255, 0),
                            2
                        )

                out.write(processed_frame)
                stats["frames_processed"] += 1

                # Hi·ªÉn th·ªã ti·∫øn tr√¨nh
                if frame_count % 30 == 0:
                    progress = (frame_count / self.total_frames) * 100
                    print(f"   Progress: {progress:.1f}% ({frame_count}/{self.total_frames})")

            except Exception as e:
                print(f"‚ö† L·ªói x·ª≠ l√Ω frame {frame_count}: {e}")
                stats["processing_errors"] += 1
                out.write(frame)  # Ghi frame g·ªëc n·∫øu c√≥ l·ªói

        # Cleanup
        out.release()

        stats["end_time"] = datetime.now().isoformat()
        print(f"\n‚úì Ho√†n th√†nh!")
        print(f"   Frames processed: {stats['frames_processed']}")
        print(f"   Characters replaced: {stats['characters_replaced']}")
        print(f"   Errors: {stats['processing_errors']}")

        return stats

    def extract_characters_info(self, output_json: str, frame_step: int = 30) -> dict:
        """
        Tr√≠ch xu·∫•t th√¥ng tin nh√¢n v·∫≠t t·ª´ video

        Args:
            output_json: ƒê∆∞·ªùng d·∫´n file JSON l∆∞u k·∫øt qu·∫£
            frame_step: B∆∞·ªõc nh·∫£y gi·ªØa c√°c frame

        Returns:
            Dictionary ch·ª©a th√¥ng tin nh√¢n v·∫≠t
        """
        info = {
            "video_info": self.get_video_info(),
            "frame_step": frame_step,
            "characters_timeline": []
        }

        print(f"\nüîç Tr√≠ch xu·∫•t th√¥ng tin nh√¢n v·∫≠t...")

        frame_count = 0
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)

        while True:
            ret, frame = self.cap.read()
            if not ret:
                break

            if frame_count % frame_step == 0:
                characters = self.detect_characters(frame)

                info["characters_timeline"].append({
                    "frame_number": frame_count,
                    "timestamp_seconds": frame_count / self.fps,
                    "characters_detected": len(characters),
                    "characters": characters
                })

                if frame_count % (frame_step * 10) == 0:
                    progress = (frame_count / self.total_frames) * 100
                    print(f"   Progress: {progress:.1f}%")

            frame_count += 1

        # L∆∞u v√†o file JSON
        with open(output_json, 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)

        print(f"‚úì ƒê√£ l∆∞u th√¥ng tin v√†o: {output_json}")

        return info

    def __del__(self):
        """Cleanup khi object b·ªã destroy"""
        if hasattr(self, 'cap'):
            self.cap.release()


def main():
    """Demo function"""
    import argparse

    parser = argparse.ArgumentParser(description='Thay th·∫ø nh√¢n v·∫≠t trong video')
    parser.add_argument('input', help='ƒê∆∞·ªùng d·∫´n video ƒë·∫ßu v√†o')
    parser.add_argument('-o', '--output', help='ƒê∆∞·ªùng d·∫´n video ƒë·∫ßu ra', default='output.mp4')
    parser.add_argument('-m', '--method',
                       choices=['blur', 'pixelate', 'color', 'image', 'info'],
                       default='blur',
                       help='Ph∆∞∆°ng ph√°p thay th·∫ø')
    parser.add_argument('-i', '--image', help='ƒê∆∞·ªùng d·∫´n ·∫£nh thay th·∫ø (cho method=image)')
    parser.add_argument('-f', '--filter', choices=['face', 'body'],
                       help='L·ªçc lo·∫°i nh√¢n v·∫≠t')
    parser.add_argument('-b', '--bbox', action='store_true',
                       help='Hi·ªÉn th·ªã bounding boxes')
    parser.add_argument('-s', '--skip', type=int, default=0,
                       help='B·ªè qua n frames ƒë·ªÉ tƒÉng t·ªëc')

    args = parser.parse_args()

    try:
        replacer = CharacterReplacer(args.input)

        if args.method == 'info':
            # Ch·ªâ tr√≠ch xu·∫•t th√¥ng tin
            output_json = args.output.replace('.mp4', '.json')
            replacer.extract_characters_info(output_json)
        else:
            # X·ª≠ l√Ω video
            stats = replacer.process_video(
                output_path=args.output,
                replacement_method=args.method,
                replacement_image=args.image,
                character_filter=args.filter,
                show_bboxes=args.bbox,
                frame_skip=args.skip
            )

            # L∆∞u stats
            stats_file = args.output.replace('.mp4', '_stats.json')
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(stats, f, indent=2, ensure_ascii=False)
            print(f"‚úì ƒê√£ l∆∞u th·ªëng k√™ v√†o: {stats_file}")

    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        return 1

    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())
