"""
Module ph√¢n t√≠ch n·ªôi dung c·∫£nh b·∫±ng AI (Claude Vision API)
"""

import anthropic
import base64
import os
from pathlib import Path
from typing import Dict, List, Optional
from tqdm import tqdm
import time


class AIAnalyzer:
    """Ph√¢n t√≠ch n·ªôi dung video b·∫±ng AI"""

    def __init__(self, api_key: Optional[str] = None, model: str = "claude-3-5-sonnet-20241022"):
        """
        Kh·ªüi t·∫°o AI Analyzer

        Args:
            api_key: Anthropic API key (n·∫øu kh√¥ng cung c·∫•p, s·∫Ω l·∫•y t·ª´ env ANTHROPIC_API_KEY)
            model: Model Claude s·ª≠ d·ª•ng
        """
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")

        if not self.api_key:
            raise ValueError(
                "C·∫ßn c√≥ ANTHROPIC_API_KEY. "
                "Vui l√≤ng set environment variable ho·∫∑c truy·ªÅn v√†o constructor"
            )

        self.client = anthropic.Anthropic(api_key=self.api_key)
        self.model = model

    def analyze_scene(
        self,
        scene_data: Dict,
        language: str = "vi",
        detail_level: str = "detailed"
    ) -> Dict:
        """
        Ph√¢n t√≠ch m·ªôt c·∫£nh d·ª±a tr√™n frames

        Args:
            scene_data: Dict ch·ª©a th√¥ng tin scene v√† ƒë∆∞·ªùng d·∫´n frames
            language: Ng√¥n ng·ªØ m√¥ t·∫£ ("vi" ho·∫∑c "en")
            detail_level: M·ª©c ƒë·ªô chi ti·∫øt ("brief", "detailed", "very_detailed")

        Returns:
            scene_data v·ªõi th√™m tr∆∞·ªùng 'description'
        """
        frames = scene_data.get('frames', {})

        if not frames:
            scene_data['description'] = "Kh√¥ng c√≥ frame ƒë·ªÉ ph√¢n t√≠ch"
            return scene_data

        # T·∫°o prompt d·ª±a tr√™n detail_level
        prompt = self._create_prompt(scene_data, language, detail_level)

        # Chu·∫©n b·ªã images cho API
        image_contents = []

        for frame_type in ['first', 'middle', 'last']:
            if frame_type in frames:
                image_path = frames[frame_type]
                image_data = self._encode_image(image_path)

                image_contents.append({
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": "image/jpeg",
                        "data": image_data,
                    },
                })

        # G·ªçi Claude API
        try:
            message_content = image_contents + [{"type": "text", "text": prompt}]

            message = self.client.messages.create(
                model=self.model,
                max_tokens=1024,
                messages=[
                    {
                        "role": "user",
                        "content": message_content
                    }
                ]
            )

            description = message.content[0].text
            scene_data['description'] = description.strip()

        except Exception as e:
            print(f"‚ö† L·ªói khi ph√¢n t√≠ch scene {scene_data['scene_number']}: {e}")
            scene_data['description'] = f"L·ªói ph√¢n t√≠ch: {str(e)}"

        return scene_data

    def analyze_all_scenes(
        self,
        scenes: List[Dict],
        language: str = "vi",
        detail_level: str = "detailed",
        delay: float = 0.5
    ) -> List[Dict]:
        """
        Ph√¢n t√≠ch t·∫•t c·∫£ c√°c c·∫£nh

        Args:
            scenes: List c√°c scene v·ªõi frames
            language: Ng√¥n ng·ªØ m√¥ t·∫£
            detail_level: M·ª©c ƒë·ªô chi ti·∫øt
            delay: Delay gi·ªØa c√°c API call (ƒë·ªÉ tr√°nh rate limit)

        Returns:
            List scenes v·ªõi descriptions
        """
        print(f"\nü§ñ ƒêang ph√¢n t√≠ch {len(scenes)} c·∫£nh b·∫±ng AI...")

        results = []

        for scene in tqdm(scenes, desc="Analyzing scenes"):
            analyzed_scene = self.analyze_scene(scene, language, detail_level)
            results.append(analyzed_scene)

            # Delay ƒë·ªÉ tr√°nh rate limit
            if delay > 0:
                time.sleep(delay)

        print("‚úì Ho√†n t·∫•t ph√¢n t√≠ch AI")

        return results

    def _create_prompt(self, scene_data: Dict, language: str, detail_level: str) -> str:
        """T·∫°o prompt cho AI d·ª±a tr√™n y√™u c·∫ßu"""

        scene_num = scene_data['scene_number']
        duration = scene_data.get('duration', 0)

        if language == "vi":
            base_prompt = f"""ƒê√¢y l√† c·∫£nh s·ªë {scene_num} trong video (th·ªùi l∆∞·ª£ng: {duration:.1f}s).

H√£y ph√¢n t√≠ch v√† m√¥ t·∫£ n·ªôi dung c·ªßa c·∫£nh n√†y m·ªôt c√°ch chi ti·∫øt.
"""

            if detail_level == "brief":
                base_prompt += "\nM√¥ t·∫£ ng·∫Øn g·ªçn (1-2 c√¢u) n·ªôi dung ch√≠nh c·ªßa c·∫£nh."

            elif detail_level == "detailed":
                base_prompt += """
M√¥ t·∫£ chi ti·∫øt theo c√°c kh√≠a c·∫°nh sau:
1. **B·ªëi c·∫£nh/M√¥i tr∆∞·ªùng**: C·∫£nh di·ªÖn ra ·ªü ƒë√¢u? (trong nh√†, ngo√†i tr·ªùi, ƒë·ªãa ƒëi·ªÉm c·ª• th·ªÉ, th·ªùi gian trong ng√†y)
2. **Nh√¢n v·∫≠t/ƒê·ªëi t∆∞·ª£ng**: C√≥ ai/c√°i g√¨ trong c·∫£nh? H·ªç ƒëang l√†m g√¨?
3. **H√†nh ƒë·ªông ch√≠nh**: Di·ªÖn bi·∫øn ch√≠nh c·ªßa c·∫£nh (n·∫øu c√≥)
4. **Chi ti·∫øt ƒë√°ng ch√∫ √Ω**: C√°c y·∫øu t·ªë quan tr·ªçng kh√°c (m√†u s·∫Øc, √°nh s√°ng, c·∫£m x√∫c, v.v.)
"""

            elif detail_level == "very_detailed":
                base_prompt += """
Ph√¢n t√≠ch C·ª∞C K·ª≤ CHI TI·∫æT c·∫£nh n√†y:

1. **B·ªëi c·∫£nh & M√¥i tr∆∞·ªùng**:
   - ƒê·ªãa ƒëi·ªÉm, kh√¥ng gian
   - Th·ªùi gian (ng√†y/ƒë√™m, m√πa n√†o)
   - ƒêi·ªÅu ki·ªán th·ªùi ti·∫øt, √°nh s√°ng

2. **Nh√¢n v·∫≠t & ƒê·ªëi t∆∞·ª£ng**:
   - S·ªë l∆∞·ª£ng ng∆∞·ªùi
   - Ngo·∫°i h√¨nh, trang ph·ª•c
   - V·ªã tr√≠, t∆∞ th·∫ø
   - Bi·ªÉu c·∫£m, c·∫£m x√∫c

3. **H√†nh ƒë·ªông & Di·ªÖn bi·∫øn**:
   - Ho·∫°t ƒë·ªông ch√≠nh
   - T∆∞∆°ng t√°c gi·ªØa c√°c nh√¢n v·∫≠t
   - Chuy·ªÉn ƒë·ªông, di chuy·ªÉn

4. **K·ªπ thu·∫≠t quay & Th·ªã gi√°c**:
   - G√≥c quay, composition
   - M√†u s·∫Øc ch·ªß ƒë·∫°o
   - √Ånh s√°ng, b√≥ng t·ªëi
   - C√°c hi·ªáu ·ª©ng ƒë·∫∑c bi·ªát (n·∫øu c√≥)

5. **√Çm thanh c√≥ th·ªÉ ƒëo√°n ƒë∆∞·ª£c**:
   - √Çm thanh m√¥i tr∆∞·ªùng
   - L·ªùi tho·∫°i (n·∫øu nh√¨n th·∫•y)
   - √Çm nh·∫°c (n·∫øu c√≥ d·∫•u hi·ªáu)

6. **√ù nghƒ©a & Ng·ªØ c·∫£nh**:
   - M·ª•c ƒë√≠ch c·ªßa c·∫£nh
   - Th√¥ng ƒëi·ªáp/√Ω nghƒ©a
   - M·ªëi li√™n h·ªá v·ªõi c·∫£nh tr∆∞·ªõc/sau (n·∫øu ƒëo√°n ƒë∆∞·ª£c)
"""

        else:  # English
            base_prompt = f"""This is scene number {scene_num} in the video (duration: {duration:.1f}s).

Please analyze and describe the content of this scene in detail.
"""

            if detail_level == "brief":
                base_prompt += "\nProvide a brief description (1-2 sentences) of the main content."

            elif detail_level == "detailed":
                base_prompt += """
Describe in detail:
1. **Setting/Environment**: Where does it take place?
2. **Characters/Objects**: Who/what is in the scene? What are they doing?
3. **Main Action**: Key events happening
4. **Notable Details**: Other important elements (colors, lighting, emotions, etc.)
"""

            elif detail_level == "very_detailed":
                base_prompt += """
Provide EXTREMELY DETAILED analysis:

1. **Setting & Environment**
2. **Characters & Objects**
3. **Actions & Events**
4. **Cinematography & Visual Elements**
5. **Potential Audio**
6. **Meaning & Context**
"""

        return base_prompt

    def _encode_image(self, image_path: str) -> str:
        """
        Encode ·∫£nh th√†nh base64

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n file ·∫£nh

        Returns:
            Base64 encoded string
        """
        with open(image_path, "rb") as image_file:
            return base64.standard_b64encode(image_file.read()).decode("utf-8")

    def analyze_with_custom_prompt(
        self,
        image_paths: List[str],
        custom_prompt: str
    ) -> str:
        """
        Ph√¢n t√≠ch v·ªõi prompt t√πy ch·ªânh

        Args:
            image_paths: List ƒë∆∞·ªùng d·∫´n ·∫£nh
            custom_prompt: Prompt t√πy ch·ªânh

        Returns:
            K·∫øt qu·∫£ ph√¢n t√≠ch
        """
        image_contents = []

        for img_path in image_paths:
            image_data = self._encode_image(img_path)
            image_contents.append({
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": "image/jpeg",
                    "data": image_data,
                },
            })

        message_content = image_contents + [{"type": "text", "text": custom_prompt}]

        message = self.client.messages.create(
            model=self.model,
            max_tokens=2048,
            messages=[
                {
                    "role": "user",
                    "content": message_content
                }
            ]
        )

        return message.content[0].text.strip()


if __name__ == "__main__":
    # Test
    try:
        analyzer = AIAnalyzer()

        # Test v·ªõi m·ªôt scene
        scene_data = {
            'scene_number': 1,
            'duration': 5.2,
            'frames': {
                'first': 'path/to/first.jpg',
                'last': 'path/to/last.jpg'
            }
        }

        result = analyzer.analyze_scene(scene_data, language="vi", detail_level="detailed")
        print("Description:", result['description'])

    except Exception as e:
        print(f"Error: {e}")
